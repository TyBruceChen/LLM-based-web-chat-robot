<html>
    <head>
        <title>Web Chatbot - Your Personal Assistant</title>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
    </head>    
    
    <body>
	<h1>Web ChatBot</h1>
	<p style="color: green;">Just for development test, continuous conversation, audio input is currently available! Set token length:8192. <b>Used Model: Llama3.2 (1B), Whisper (72.6M)</b></p>
	<p>If error occurs, try access <a href="/session_out">/session_out</a>.</p><hr><hr>
	<section id="content_section">
	<h3>Text Input:</h3>
	<form action="" method="POST" style="margin:auto; border: 3px solid gray; padding: 5px; width: 98%;">
		<i style="color:blue;">The Bot's role</i> (指定AI扮演的角色) (by specifying this, the conversation will be professional and accurate): <input type="text" name="bot_role" value="You are a friendly chatbot who always responds in the style of a research assistant in AI Lab" style="width: 60%;">
	    	<br><br>
		<p style='color: blue;'><i>Your question: </i></p><input type="text" name="question" style='width: 90%;'>
            	<input type="submit">
		</div>
        </form>
	<br>
	<h3>Or Audio Iput:</h3>
	<button id="recordButton">Start Speak Recording</button>
    <button id="stopButton" disabled>Stop Speak Recording</button>
    <script>
        let mediaRecorder;
        let audioChunks = [];

        document.getElementById('recordButton').onclick = async () => {
            // Request access to microphone
		let stream;
		if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia){
			try{
				stream = await navigator.mediaDevices.getUserMedia({ audio: true });
           			console.log("Audio Stream Started", stream);
			}catch(error){
				console.error("Error accessing media devices", error);
			}
	}else{
		alert("getUserMedia is not supported by this browser");
	}
	    //console.log('1',stream);
	    mediaRecorder = new MediaRecorder(stream);
	    //console.log('2');
            mediaRecorder.ondataavailable = event => {
                audioChunks.push(event.data);
            };

            mediaRecorder.onstop = () => {
                const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                uploadAudio(audioBlob);  // Call function to upload the audio
                audioChunks = []; // Reset for the next recording
            };

            mediaRecorder.start();
            document.getElementById('recordButton').disabled = true;
            document.getElementById('stopButton').disabled = false;
        };

        document.getElementById('stopButton').onclick = () => {
            mediaRecorder.stop();
            document.getElementById('recordButton').disabled = false;
            document.getElementById('stopButton').disabled = true;
        };

        function uploadAudio(audioBlob) {
            const formData = new FormData();
            formData.append('file', audioBlob, 'recording.wav');  // Append audio file to FormData

            fetch('/chatbot_v1.html', {
                method: 'POST',
                body: formData
            })
	    .then(response => {
		if (!response.ok){
			throw new Error('Network response error!');
		}
		return response.text();
	    })
            .then(html => {
                //document.body.innerHTML = html;              		    
		window.location.href = window.location.href;
	    })
            .catch(error => console.error('Error:', error));
        }
    </script>
    </section>
    	{% if answer %}<br>
                replaced_part_
        {% endif %}
	<br><hr>
	<form action="" method="POST">
		<input type="submit" name="ClearChat" value="Clear History Chat">
	</form>
	<footer>
		<h5 style="position: fixed; right: 10px; bottom: 90%;">Deployed through USTC's RTX 3080 (10GB), by <a href='https://github.com/TyBruceChen/LLM-based-web-chat-robot/'>TyBruce</a><br>Contact: <a href="mailto:ty_bruce.chen@outlook.com">ty_bruce.chen@outlook.com</a></h5>
	</footer>
    </body>
</html>
